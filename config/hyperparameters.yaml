num_train_epochs: 3
per_device_train_batch_size: 1
per_device_eval_batch_size: 1
learning_rate: 5e-5
evaluation_strategy: 'steps'
eval_steps: 1500
save_strategy: 'steps'  # Ensure this is included
save_steps: 1500
logging_steps: 50
save_total_limit: 2
load_best_model_at_end: True
metric_for_best_model: 'eval_loss'
greater_is_better: False
semantic_weight: 0.5
hidden_weight: 0.5
fp16: True
gradient_accumulation_steps: 4
gradient_checkpointing: True