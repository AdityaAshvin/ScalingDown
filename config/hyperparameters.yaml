num_train_epochs: 4
per_device_train_batch_size: 3
per_device_eval_batch_size: 1
learning_rate: 5e-5
evaluation_strategy: 'no' # cannot do evaluation due to memory issue
eval_steps: 0
save_strategy: 'epoch'
save_steps: 0
logging_steps: 100
save_total_limit: 2
load_best_model_at_end: False # cannot do evaluation due to memory issue
metric_for_best_model: 'eval_loss'
greater_is_better: False
semantic_weight: 0.5
hidden_weight: 0.5
bf16: False
fp16: True
gradient_accumulation_steps: 4
gradient_checkpointing: True
eval_accumulation_steps: 1